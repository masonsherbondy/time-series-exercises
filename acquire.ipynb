{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import mason_functions as mf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a987e017",
   "metadata": {},
   "source": [
    "# Acquire Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ae9520",
   "metadata": {},
   "source": [
    "1. Using the code from the lesson as a guide and the REST API from https://python.zgulde.net/api/v1/items as we did in the lesson, create a dataframe named items that has all of the data for items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf359e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get response using requests library\n",
    "response = requests.get('https://python.zgulde.net/api/v1/items')\n",
    "\n",
    "#assign json data to variable\n",
    "data = response.json()\n",
    "\n",
    "#verify data type\n",
    "print(type(data))\n",
    "\n",
    "#verify data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab043b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check api keys\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b4ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign dataframe to data acquired\n",
    "items = pd.DataFrame(data['payload']['items'])\n",
    "\n",
    "#check it\n",
    "items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get response utilizing requests library from Zach's API\n",
    "response = requests.get('https://python.zgulde.net/api/v1/items?page=2')\n",
    "\n",
    "#assign variable to json data\n",
    "data = response.json()\n",
    "\n",
    "#concatenate previous dataframe with second-page data\n",
    "items = pd.concat([items, pd.DataFrame(data['payload']['items'])])\n",
    "\n",
    "#check it\n",
    "items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b4db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get response from Zach's API using requests library\n",
    "response = requests.get('https://python.zgulde.net/api/v1/items?page=3')\n",
    "\n",
    "#assign variable to json data\n",
    "data = response.json()\n",
    "\n",
    "#concatenate previous dataframe with new data from 3rd page\n",
    "items = pd.concat([items, pd.DataFrame(data['payload']['items'])])\n",
    "\n",
    "#check it\n",
    "items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61371410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change max rows to a high number for viewability\n",
    "pd.options.display.max_rows = 69\n",
    "\n",
    "#view dataframe\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign missing values to numbers 0 to 9\n",
    "#items.loc[40:, 'index'] = range(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify\n",
    "#items.loc[40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf04276",
   "metadata": {},
   "source": [
    "2. Do the same thing, but for stores (https://python.zgulde.net/api/v1/stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a response from Zach's API using the requests library\n",
    "response = requests.get('https://python.zgulde.net/api/v1/stores')\n",
    "\n",
    "#assign variable to json data\n",
    "data = response.json()\n",
    "\n",
    "#verify data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff791a",
   "metadata": {},
   "source": [
    "There is only one page here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da37d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign variable to datafarme\n",
    "stores = pd.DataFrame(data['payload']['stores'])\n",
    "stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking\n",
    "stores.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0563f",
   "metadata": {},
   "source": [
    "3. Extract the data for sales (https://python.zgulde.net/api/v1/sales). There are a lot of pages of data here, so your code will need to be a little more complex. Your code should continue fetching data from the next page until all of the data is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb93bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#request response from api using requests module\n",
    "response = requests.get('https://python.zgulde.net/api/v1/sales')\n",
    "\n",
    "#assign variable to json data\n",
    "data = response.json()\n",
    "\n",
    "#verify data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377df79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dataframe with json data\n",
    "sales = pd.DataFrame(data['payload']['sales'])\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1edbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign variable to max page number\n",
    "max_page = data['payload']['max_page']\n",
    "max_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0353dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#commence loop\n",
    "for n in range(2, max_page + 1):\n",
    "    response = requests.get(f'https://python.zgulde.net/api/v1/sales?page={n}')\n",
    "    data = response.json()\n",
    "    mein_sales = pd.DataFrame(data['payload']['sales'])\n",
    "    sales = pd.concat([sales, mein_sales])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8351d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check it\n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c466fb",
   "metadata": {},
   "source": [
    "4. Save the data in your files to local csv files so that it will be faster to access in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aff146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pandas .to_csv method to write dataframes into .csv's\n",
    "items.to_csv('zachs_items.csv')\n",
    "stores.to_csv('zachs_stores.csv')\n",
    "sales.to_csv('zachs_sales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ef570",
   "metadata": {},
   "source": [
    "5. Combine the data from your three separate dataframes into one large dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b4d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge first two tables with an inner join based on key columns\n",
    "join = pd.merge(sales,\n",
    "                items,\n",
    "                how = 'inner',\n",
    "                left_on = 'item',\n",
    "                right_on = 'item_id'\n",
    "               )\n",
    "#check it\n",
    "join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb70de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the merged table and the stores table using the store number as a foreign key\n",
    "super_frame = pd.merge(join,\n",
    "                       stores,\n",
    "                       how = 'inner',\n",
    "                       left_on = 'store',\n",
    "                       right_on = 'store_id'\n",
    "                      )\n",
    "#checking\n",
    "super_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking\n",
    "super_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69847a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking again\n",
    "super_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6eeca",
   "metadata": {},
   "source": [
    "6. Acquire the Open Power Systems Data for Germany, which has been rapidly expanding its renewable energy production in recent years. The data set includes country-wide totals of electricity consumption, wind power production, and solar power production for 2006-2017. You can get the data here: https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv link with pandas .read_csv function\n",
    "power = pd.read_csv('https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv')\n",
    "\n",
    "#check it\n",
    "power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b26b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking\n",
    "power.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93646179",
   "metadata": {},
   "source": [
    "7. Make sure all the work that you have done above is reproducible. That is, you should put the code above into separate functions in the acquire.py file and be able to re-run the functions and get the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zachs_pages(payload):\n",
    "    \n",
    "    #get response from api\n",
    "    response = requests.get(f'https://python.zgulde.net/api/v1/{payload}?page=1')\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data['payload'][payload])\n",
    "    \n",
    "    #assign variable to max page number\n",
    "    max_page = data['payload']['max_page']\n",
    "    \n",
    "    #commence loop\n",
    "    for n in range(2, max_page + 1):\n",
    "        response = requests.get(f'https://python.zgulde.net/api/v1/{payload}?page={n}')\n",
    "        data = response.json()\n",
    "        df_0 = pd.DataFrame(data['payload'][payload])\n",
    "        df = pd.concat([df, df_0])\n",
    "    \n",
    "    #return finished frame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "items = get_zachs_pages('items')\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a67b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "stores = get_zachs_pages('stores')\n",
    "stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b59d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items():\n",
    "    \n",
    "    #set up if-conditional to see if a .csv is available\n",
    "    if os.path.isfile('zachs_items.csv'):\n",
    "        \n",
    "        #if there is, read the data into a dataframe\n",
    "        items = pd.read_csv('zachs_items.csv', index_col = 0)\n",
    "    else:\n",
    "        #get items\n",
    "        items = get_zachs_pages('items')\n",
    "        \n",
    "        #write data to frame\n",
    "        items = pd.DataFrame(items)\n",
    "        \n",
    "        #cache data in .csv\n",
    "        items.to_csv('zachs_items.csv')\n",
    "    \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4685b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stores():\n",
    "    \n",
    "    #set up if-conditional to see if a .csv is available\n",
    "    if os.path.isfile('zachs_stores.csv'):\n",
    "        \n",
    "        #if there is, read the data into a dataframe\n",
    "        stores = pd.read_csv('zachs_stores.csv', index_col = 0)\n",
    "    else:\n",
    "        #get stores\n",
    "        stores = get_zachs_pages('stores')\n",
    "        \n",
    "        #write data to frame\n",
    "        stores = pd.DataFrame(stores)\n",
    "        \n",
    "        #cache data in .csv\n",
    "        stores.to_csv('zachs_stores.csv')\n",
    "    \n",
    "    return stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abec563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sales():\n",
    "    \n",
    "    #set up if-conditional to see if a .csv is available\n",
    "    if os.path.isfile('zachs_sales.csv'):\n",
    "        \n",
    "        #if there is, read the data into a dataframe\n",
    "        sales = pd.read_csv('zachs_sales.csv', index_col = 0)\n",
    "    else:\n",
    "        #get sales\n",
    "        sales = get_zachs_pages('sales')\n",
    "        \n",
    "        #write data to frame\n",
    "        sales = pd.DataFrame(sales)\n",
    "        \n",
    "        #cache data in .csv\n",
    "        sales.to_csv('zachs_sales.csv')\n",
    "    \n",
    "    return sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6888651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_store_frame(items, stores, sales):\n",
    "    \n",
    "    #merge first two tables with an inner join based on key columns\n",
    "    join = pd.merge(sales,\n",
    "                    items,\n",
    "                    how = 'inner',\n",
    "                    left_on = 'item',\n",
    "                    right_on = 'item_id'\n",
    "                   )\n",
    "    \n",
    "    #merge the merged table and the stores table using the store number as a foreign key\n",
    "    super_frame = pd.merge(join,\n",
    "                           stores,\n",
    "                           how = 'inner',\n",
    "                           left_on = 'store',\n",
    "                           right_on = 'store_id'\n",
    "                          )\n",
    "    \n",
    "    return super_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8992c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power():\n",
    "    \n",
    "    #read .csv with pandas .read_csv function\n",
    "    power = pd.read_csv('https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv')\n",
    "\n",
    "    #return df\n",
    "    return power"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
